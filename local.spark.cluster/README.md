- ref: https://www.kdnuggets.com/2020/07/apache-spark-cluster-docker.html

docker-compose up



- JupyterLab at localhost:8888;
- Spark master at http://localhost:8470/;
- Spark worker I at http://localhost:8471/;
- Spark worker II at http://localhost:8472/;
- Spark worker III at http://localhost:8473/;


### S3 connection
- https://stackoverflow.com/questions/30385981/how-to-access-s3a-files-from-apache-spark
- https://sparkour.urizone.net/recipes/using-s3/
- https://medium.com/@bogdan.cojocar/how-to-read-parquet-data-from-s3-using-the-s3a-protocol-and-temporary-credentials-in-pyspark-f94071bf8c6a